---
title: "Choose your own splitting criteria"
subtitle: "An adventure with random forests"
author: "Andee Kaplan"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    fig_caption: true
bibliography: biblio.bib
vignette: >
  %\VignetteIndexEntry{Choose your own splitting criteria}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

#Background

The random forest [@breiman2001random] is an ensemble method that combines bagged (bootstap aggregated) classification and regression trees with a random variable selection at each node in the tree. This methodology is implemented in `R` [@R] in the `randomForest` package [@randomForest]. The random forest methodology is a general framework for building a model by combining trees, however its implementation is very specific. Within the `randomForest` package, a Gini splitting criteria is used as the only possible splitting mechanism within the trees.

The `forestr` [@forestr] implements the random forest methodology with a choice of splitting criteria, namely:

  - Gini,
  - Information,
  - One-sided Extremes, and
  - One-sided Purity.
  
The last two splitting criteria are introduced by Buja and Lee [-@buja2001data] as a means to "identify pure or extreme buckets" in the data.

#Why

You may think to yourself, "Why would I need this? The `randomForest` package works well and is blazing fast!" I would agree. If Gini is your splitting criteria of choice and your data are fairly balanced, then I would recommend using `randomForest`. If, however, your data is not evenly spread across the classification buckets or there is a particular class of data that you care more about classifying correctly (especially if it is a small minority of cases), then you may turn to a one-sided extremes or one-sided purity splitting function. This is the case often with detection problems, for example cancer detection in pations or detection of the Higgs particle from measurements by particle detectors in an accelerator.

#Higgs Example


#Implementation

The `forestr` package is written entirely in `R`and uses a modified `rpart` package [@rpart] to include the additional splitting criteria. The modified `rpart` can be found at http://github.com/andeek/rpart and installed using the command 

```r
devtools::install_github("andeek/rpart")
```

The modifications to `rpart` for the additional splitting functions were first introduced in the package `itree` [@itree], however this package was build on an old and slightly unstable version of `rpart`, making it unusable as is within the `forestr` framework. Fortunately, `rpart` allows for the addition of user defined splitting criterion using either `C` functions or `R` functions written by the user. The three functions a user must define are

init

:   The initialization function that initializes the parameters and data passed to the splitting function

eval

:   The evaluation function that creates a label for each node and evaluated the deviance at that node

split
    
:   The splitting function is the workhorse function that actually attempts to find the split point for the data based on a variable

As such, the modified `rpart` contains the additional functions provided from the `itree` package, but within the more stable current release of `rpart`, version 4.1-9.

#References
